{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377afde0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "def generate_stratified_dataset(\n",
    "    csv_path=r'sampledata_2.csv', \n",
    "    groundtruth_folder=r'groundtruth',\n",
    "    output_file='dataset_selection_result.xlsx',\n",
    "    target_total=3\n",
    "):\n",
    "    # --- 1. Read and preprocess sampledata.csv ---\n",
    "    print(\"Reading the original data table...\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found {csv_path}\")\n",
    "        return\n",
    "\n",
    "    # Assume that file_name in CSV is {name}.html, we need to extract {name}\n",
    "    # Using os.path.splitext can safely handle filenames containing '.' (if there are other dots besides the extension)\n",
    "    df['clean_name'] = df['file_name'].apply(lambda x: os.path.splitext(x)[0])\n",
    "    \n",
    "    # Check for duplicate clean_name to prevent matching confusion\n",
    "    if df['clean_name'].duplicated().any():\n",
    "        print(\"Warning: There are duplicate base filenames in sampledata.csv, which may affect matching accuracy.\")\n",
    "\n",
    "    # --- 2. Read and preprocess the groundtruth folder ---\n",
    "    print(\"Scanning the Groundtruth folder...\")\n",
    "    if not os.path.exists(groundtruth_folder):\n",
    "        print(f\"Error: Folder not found {groundtruth_folder}\")\n",
    "        return\n",
    "\n",
    "    # Get all .zip files in the folder\n",
    "    existing_files = glob.glob(os.path.join(groundtruth_folder, '*.zip'))\n",
    "    # Extract base filenames {name}, be careful with path separators\n",
    "    existing_basenames = [os.path.splitext(os.path.basename(f))[0] for f in existing_files]\n",
    "    \n",
    "    print(f\"There are {len(existing_basenames)} files in Groundtruth.\")\n",
    "\n",
    "    # --- 3. Mark existing data ---\n",
    "    # Mark in the dataframe whether the row data already exists in groundtruth\n",
    "    df['in_groundtruth'] = df['clean_name'].isin(existing_basenames)\n",
    "    \n",
    "    # Check if there are groundtruth files not found in CSV (to prevent filename mismatch issues)\n",
    "    matched_count = df['in_groundtruth'].sum()\n",
    "    if matched_count < len(existing_basenames):\n",
    "        missing = set(existing_basenames) - set(df[df['in_groundtruth']]['clean_name'])\n",
    "        print(f\"Warning: {len(existing_basenames) - matched_count} files in Groundtruth were not found in CSV.\")\n",
    "        print(f\"Unmatched examples: {list(missing)[:5]}\")\n",
    "\n",
    "    # --- 4. Calculate distribution and target quotas ---\n",
    "    # Count the topic distribution ratio of the 3500 data points\n",
    "    total_count = len(df)\n",
    "    topic_dist = df['topic'].value_counts(normalize=True) # Get proportions\n",
    "    \n",
    "    # Initialize statistics results list\n",
    "    stats_list = []\n",
    "    files_to_add_indices = []\n",
    "\n",
    "    print(\"Calculating quotas for each Topic and filling data...\")\n",
    "    \n",
    "    # Iterate through each topic (total 24)\n",
    "    for topic, ratio in topic_dist.items():\n",
    "        # 1. Calculate how many should theoretically be in the 400 data points for this topic (round to nearest)\n",
    "        target_count = int(round(target_total * ratio))\n",
    "        if target_count == 0: target_count = 1 # Ensure at least 1 per category to avoid loss of small categories\n",
    "        \n",
    "        # 2. Get all data rows for this topic\n",
    "        topic_rows = df[df['topic'] == topic]\n",
    "        \n",
    "        # 3. Count how many in this topic are already in groundtruth\n",
    "        current_existing = topic_rows[topic_rows['in_groundtruth'] == True]\n",
    "        current_count = len(current_existing)\n",
    "        \n",
    "        # 4. Calculate the gap\n",
    "        needed = target_count - current_count\n",
    "        \n",
    "        added_count = 0\n",
    "        \n",
    "        if needed > 0:\n",
    "            # Need to add data\n",
    "            # Randomly sample from data in this topic that are not in groundtruth\n",
    "            candidates = topic_rows[topic_rows['in_groundtruth'] == False]\n",
    "            \n",
    "            if len(candidates) >= needed:\n",
    "                # Enough candidates, random sample (set random_state for reproducibility)\n",
    "                sampled = candidates.sample(n=needed, random_state=42)\n",
    "                files_to_add_indices.extend(sampled.index.tolist())\n",
    "                added_count = needed\n",
    "            else:\n",
    "                # Not enough candidates (shouldn't happen theoretically unless 3500 data itself is insufficient), select all\n",
    "                files_to_add_indices.extend(candidates.index.tolist())\n",
    "                added_count = len(candidates)\n",
    "                print(f\"Note: Insufficient data for Topic '{topic}', unable to fully meet target quota.\")\n",
    "        \n",
    "        # Record statistics\n",
    "        stats_list.append({\n",
    "            'Topic': topic,\n",
    "            'Original_Ratio': f\"{ratio:.2%}\",\n",
    "            'Target_Count_Total': target_count,\n",
    "            'Existing_In_Groundtruth': current_count,\n",
    "            'To_Add': added_count,\n",
    "            'Final_Total': current_count + added_count,\n",
    "            'Status': 'Over Budget' if needed < 0 else 'Filled'\n",
    "        })\n",
    "\n",
    "    # --- 5. Generate result DataFrame ---\n",
    "    \n",
    "    # Sheet 1: Distribution of existing 100+ data points\n",
    "    df_existing = df[df['in_groundtruth'] == True][['file_name', 'topic', 'category', 'clean_name']]\n",
    "    \n",
    "    # Sheet 2: List of file_names to add\n",
    "    df_to_add = df.loc[files_to_add_indices][['file_name', 'topic', 'category']]\n",
    "    \n",
    "    # Sheet 3: Overall distribution statistics table\n",
    "    df_stats = pd.DataFrame(stats_list)\n",
    "    # Adjust column order for easy viewing\n",
    "    df_stats = df_stats[['Topic', 'Original_Ratio', 'Target_Count_Total', 'Existing_In_Groundtruth', 'To_Add', 'Final_Total', 'Status']]\n",
    "\n",
    "    # Can also generate Sheet 4: Complete list of final 400 data points\n",
    "    df_final_list = pd.concat([df_existing, df_to_add])\n",
    "\n",
    "    # --- 6. Write to Excel ---\n",
    "    print(f\"Writing results to {output_file}...\")\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        df_existing.to_excel(writer, sheet_name='Existing_Distribution', index=False)\n",
    "        df_to_add.to_excel(writer, sheet_name='Files_To_Add', index=False)\n",
    "        df_stats.to_excel(writer, sheet_name='Distribution_Summary', index=False)\n",
    "        df_final_list.to_excel(writer, sheet_name='Final_Full_List', index=False)\n",
    "\n",
    "    print(\"Task completed!\")\n",
    "    print(f\"Total existing data: {len(df_existing)}\")\n",
    "    print(f\"Suggested data to add: {len(df_to_add)}\")\n",
    "    print(f\"Expected final total: {len(df_final_list)}\")\n",
    "\n",
    "# --- Execute function ---\n",
    "# Ensure sampledata.csv and groundtruth folder are in the current directory\n",
    "if __name__ == \"__main__\":\n",
    "    generate_stratified_dataset()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
