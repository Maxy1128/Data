{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377afde0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "\n",
    "def generate_stratified_dataset(\n",
    "    csv_path=r'sampledata_2.csv', \n",
    "    groundtruth_folder=r'groundtruth',\n",
    "    output_file='dataset_selection_result.xlsx',\n",
    "    target_total=3\n",
    "):\n",
    "    # --- 1. Read and preprocess sampledata.csv ---\n",
    "    print(\"Reading the original data table...\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found {csv_path}\")\n",
    "        return\n",
    "\n",
    "    # Assume that file_name in CSV is {name}.html, we need to extract {name}\n",
    "    # Using os.path.splitext can safely handle filenames containing '.' (if there are other dots besides the extension)\n",
    "    df['clean_name'] = df['file_name'].apply(lambda x: os.path.splitext(x)[0])\n",
    "    \n",
    "    # Check for duplicate clean_name to prevent matching confusion\n",
    "    if df['clean_name'].duplicated().any():\n",
    "        print(\"Warning: There are duplicate base filenames in sampledata.csv, which may affect matching accuracy.\")\n",
    "\n",
    "    # --- 2. Read and preprocess the groundtruth folder ---\n",
    "    print(\"Scanning the Groundtruth folder...\")\n",
    "    if not os.path.exists(groundtruth_folder):\n",
    "        print(f\"Error: Folder not found {groundtruth_folder}\")\n",
    "        return\n",
    "\n",
    "    # Get all .zip files in the folder\n",
    "    existing_files = glob.glob(os.path.join(groundtruth_folder, '*.zip'))\n",
    "    # Extract base filenames {name}, be careful with path separators\n",
    "    existing_basenames = [os.path.splitext(os.path.basename(f))[0] for f in existing_files]\n",
    "    \n",
    "    print(f\"There are {len(existing_basenames)} files in Groundtruth.\")\n",
    "\n",
    "    # --- 3. Mark existing data ---\n",
    "    # Mark in the dataframe whether the row data already exists in groundtruth\n",
    "    df['in_groundtruth'] = df['clean_name'].isin(existing_basenames)\n",
    "    \n",
    "    # Check if there are groundtruth files not found in CSV (to prevent filename mismatch issues)\n",
    "    matched_count = df['in_groundtruth'].sum()\n",
    "    if matched_count < len(existing_basenames):\n",
    "        missing = set(existing_basenames) - set(df[df['in_groundtruth']]['clean_name'])\n",
    "        print(f\"Warning: {len(existing_basenames) - matched_count} files in Groundtruth were not found in CSV.\")\n",
    "        print(f\"Unmatched examples: {list(missing)[:5]}\")\n",
    "\n",
    "    # --- 4. Calculate distribution and target quotas ---\n",
    "    # Count the topic distribution ratio of the 3500 data points\n",
    "    total_count = len(df)\n",
    "    topic_dist = df['topic'].value_counts(normalize=True) # Get proportions\n",
    "    \n",
    "    # Initialize statistics results list\n",
    "    stats_list = []\n",
    "    files_to_add_indices = []\n",
    "\n",
    "    print(\"Calculating quotas for each Topic and filling data...\")\n",
    "    \n",
    "    # Iterate through each topic (total 24)\n",
    "    for topic, ratio in topic_dist.items():\n",
    "        # 1. Calculate how many should theoretically be in the 400 data points for this topic (round to nearest)\n",
    "        target_count = int(round(target_total * ratio))\n",
    "        if target_count == 0: target_count = 1 # Ensure at least 1 per category to avoid loss of small categories\n",
    "        \n",
    "        # 2. Get all data rows for this topic\n",
    "        topic_rows = df[df['topic'] == topic]\n",
    "        \n",
    "        # 3. Count how many in this topic are already in groundtruth\n",
    "        current_existing = topic_rows[topic_rows['in_groundtruth'] == True]\n",
    "        current_count = len(current_existing)\n",
    "        \n",
    "        # 4. Calculate the gap\n",
    "        needed = target_count - current_count\n",
    "        \n",
    "        added_count = 0\n",
    "        \n",
    "        if needed > 0:\n",
    "            # Need to add data\n",
    "            # Randomly sample from data in this topic that are not in groundtruth\n",
    "            candidates = topic_rows[topic_rows['in_groundtruth'] == False]\n",
    "            \n",
    "            if len(candidates) >= needed:\n",
    "                # Enough candidates, random sample (set random_state for reproducibility)\n",
    "                sampled = candidates.sample(n=needed, random_state=42)\n",
    "                files_to_add_indices.extend(sampled.index.tolist())\n",
    "                added_count = needed\n",
    "            else:\n",
    "                # Not enough candidates (shouldn't happen theoretically unless 3500 data itself is insufficient), select all\n",
    "                files_to_add_indices.extend(candidates.index.tolist())\n",
    "                added_count = len(candidates)\n",
    "                print(f\"Note: Insufficient data for Topic '{topic}', unable to fully meet target quota.\")\n",
    "        \n",
    "        # Record statistics\n",
    "        stats_list.append({\n",
    "            'Topic': topic,\n",
    "            'Original_Ratio': f\"{ratio:.2%}\",\n",
    "            'Target_Count_Total': target_count,\n",
    "            'Existing_In_Groundtruth': current_count,\n",
    "            'To_Add': added_count,\n",
    "            'Final_Total': current_count + added_count,\n",
    "            'Status': 'Over Budget' if needed < 0 else 'Filled'\n",
    "        })\n",
    "\n",
    "    # --- 5. Generate result DataFrame ---\n",
    "    \n",
    "    # Sheet 1: Distribution of existing 100+ data points\n",
    "    df_existing = df[df['in_groundtruth'] == True][['file_name', 'topic', 'category', 'clean_name']]\n",
    "    \n",
    "    # Sheet 2: List of file_names to add\n",
    "    df_to_add = df.loc[files_to_add_indices][['file_name', 'topic', 'category']]\n",
    "    \n",
    "    # Sheet 3: Overall distribution statistics table\n",
    "    df_stats = pd.DataFrame(stats_list)\n",
    "    # Adjust column order for easy viewing\n",
    "    df_stats = df_stats[['Topic', 'Original_Ratio', 'Target_Count_Total', 'Existing_In_Groundtruth', 'To_Add', 'Final_Total', 'Status']]\n",
    "\n",
    "    # Can also generate Sheet 4: Complete list of final 400 data points\n",
    "    df_final_list = pd.concat([df_existing, df_to_add])\n",
    "\n",
    "    # --- 6. Write to Excel ---\n",
    "    print(f\"Writing results to {output_file}...\")\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        df_existing.to_excel(writer, sheet_name='Existing_Distribution', index=False)\n",
    "        df_to_add.to_excel(writer, sheet_name='Files_To_Add', index=False)\n",
    "        df_stats.to_excel(writer, sheet_name='Distribution_Summary', index=False)\n",
    "        df_final_list.to_excel(writer, sheet_name='Final_Full_List', index=False)\n",
    "\n",
    "    print(\"Task completed!\")\n",
    "    print(f\"Total existing data: {len(df_existing)}\")\n",
    "    print(f\"Suggested data to add: {len(df_to_add)}\")\n",
    "    print(f\"Expected final total: {len(df_final_list)}\")\n",
    "\n",
    "# --- Execute function ---\n",
    "# Ensure sampledata.csv and groundtruth folder are in the current directory\n",
    "if __name__ == \"__main__\":\n",
    "    generate_stratified_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976931b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import zipfile  # 引入 zipfile 库\n",
    "import math\n",
    "\n",
    "def generate_stratified_dataset(\n",
    "    csv_path=r'C:\\Users\\MaXin\\Desktop\\HSBC\\GroundTruth_Dataset\\sampledata_2.csv', \n",
    "    # 修改这里：指向具体的 zip 文件路径\n",
    "    groundtruth_zip_path=r'C:\\Users\\MaXin\\Desktop\\HSBC\\GroundTruth_Dataset\\groundtruth.zip',\n",
    "    output_file='dataset_selection_result.xlsx',\n",
    "    target_total=3 # 注意：你这里设的是3，正式跑可能要改成400\n",
    "):\n",
    "    # --- 1. 读取并预处理 sampledata.csv ---\n",
    "    print(\"正在读取原始数据表...\")\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: 找不到文件 {csv_path}\")\n",
    "        return\n",
    "\n",
    "    # 假设 CSV 中的 file_name 是 {name}.html，我们需要提取 {name}\n",
    "    df['clean_name'] = df['file_name'].apply(lambda x: os.path.splitext(x)[0])\n",
    "    \n",
    "    if df['clean_name'].duplicated().any():\n",
    "        print(\"Warning: sampledata.csv 中存在重复的基础文件名，可能会影响匹配准确性。\")\n",
    "\n",
    "    # --- 2. 直接读取 Groundtruth Zip 文件 (无需解压) ---\n",
    "    print(\"正在扫描 Groundtruth Zip 包...\")\n",
    "    if not os.path.exists(groundtruth_zip_path):\n",
    "        print(f\"Error: 找不到压缩文件 {groundtruth_zip_path}\")\n",
    "        return\n",
    "\n",
    "    existing_basenames = []\n",
    "    \n",
    "    try:\n",
    "        # 使用 zipfile 打开压缩包\n",
    "        with zipfile.ZipFile(groundtruth_zip_path, 'r') as z:\n",
    "            # 获取压缩包内所有文件的列表\n",
    "            all_files_in_zip = z.namelist()\n",
    "            \n",
    "            for f in all_files_in_zip:\n",
    "                # 过滤掉文件夹路径（以/结尾）和可能存在的隐藏文件（如 __MACOSX）\n",
    "                if f.endswith('/') or '__MACOSX' in f:\n",
    "                    continue\n",
    "                \n",
    "                # 获取文件名（去掉路径前缀，例如 \"groundtruth/abc.zip\" -> \"abc.zip\"）\n",
    "                filename = os.path.basename(f)\n",
    "                \n",
    "                # 如果文件名为空（可能是纯路径），跳过\n",
    "                if not filename:\n",
    "                    continue\n",
    "                    \n",
    "                # 去掉扩展名，例如 \"abc.zip\" -> \"abc\"\n",
    "                # 这里假设压缩包里是 .zip 或 .html 文件，只要文件名能对上就行\n",
    "                basename = os.path.splitext(filename)[0]\n",
    "                existing_basenames.append(basename)\n",
    "                \n",
    "    except zipfile.BadZipFile:\n",
    "        print(\"Error: 无法读取 zip 文件，文件可能已损坏。\")\n",
    "        return\n",
    "\n",
    "    print(f\"Groundtruth Zip 包中包含 {len(existing_basenames)} 个有效文件。\")\n",
    "\n",
    "    # --- 3. 标记现有数据 ---\n",
    "    # 在 dataframe 中标记该行数据是否已存在于 groundtruth 中\n",
    "    df['in_groundtruth'] = df['clean_name'].isin(existing_basenames)\n",
    "    \n",
    "    # 检查是否有 groundtruth 文件在 CSV 中未找到\n",
    "    matched_count = df['in_groundtruth'].sum()\n",
    "    # 注意：这里只做简单对比，因为 zip 里可能包含一些非数据文件\n",
    "    print(f\"CSV 中已匹配到 {matched_count} 条 Groundtruth 数据。\")\n",
    "\n",
    "    # --- 4. 计算分布并填充目标名额 ---\n",
    "    total_count = len(df)\n",
    "    topic_dist = df['topic'].value_counts(normalize=True) # 获取比例\n",
    "    \n",
    "    stats_list = []\n",
    "    files_to_add_indices = []\n",
    "\n",
    "    print(\"正在计算各 Topic 配额并填充数据...\")\n",
    "    \n",
    "    for topic, ratio in topic_dist.items():\n",
    "        # 1. 计算该 Topic 理论上在目标总数中应占多少个 (四舍五入)\n",
    "        target_count = int(round(target_total * ratio))\n",
    "        if target_count == 0: target_count = 1 \n",
    "        \n",
    "        # 2. 获取该 Topic 的所有数据行\n",
    "        topic_rows = df[df['topic'] == topic]\n",
    "        \n",
    "        # 3. 统计该 Topic 下已经存在于 groundtruth 的数量\n",
    "        current_existing = topic_rows[topic_rows['in_groundtruth'] == True]\n",
    "        current_count = len(current_existing)\n",
    "        \n",
    "        # 4. 计算缺口\n",
    "        needed = target_count - current_count\n",
    "        \n",
    "        added_count = 0\n",
    "        \n",
    "        if needed > 0:\n",
    "            # 需要补充数据\n",
    "            # 从该 Topic 中未在 groundtruth 的数据里随机抽取\n",
    "            candidates = topic_rows[topic_rows['in_groundtruth'] == False]\n",
    "            \n",
    "            if len(candidates) >= needed:\n",
    "                # 候选够多，随机抽 (设置 random_state 保证可复现)\n",
    "                sampled = candidates.sample(n=needed, random_state=42)\n",
    "                files_to_add_indices.extend(sampled.index.tolist())\n",
    "                added_count = needed\n",
    "            else:\n",
    "                # 候选不够，全选\n",
    "                files_to_add_indices.extend(candidates.index.tolist())\n",
    "                added_count = len(candidates)\n",
    "                print(f\"Note: Topic '{topic}' 数据不足，无法完全满足目标配额。\")\n",
    "        \n",
    "        stats_list.append({\n",
    "            'Topic': topic,\n",
    "            'Original_Ratio': f\"{ratio:.2%}\",\n",
    "            'Target_Count_Total': target_count,\n",
    "            'Existing_In_Groundtruth': current_count,\n",
    "            'To_Add': added_count,\n",
    "            'Final_Total': current_count + added_count,\n",
    "            'Status': 'Over Budget' if needed < 0 else 'Filled'\n",
    "        })\n",
    "\n",
    "    # --- 5. 生成结果 DataFrame ---\n",
    "    \n",
    "    # Sheet 1: 现有的分布情况\n",
    "    df_existing = df[df['in_groundtruth'] == True][['file_name', 'topic', 'category', 'clean_name']]\n",
    "    \n",
    "    # Sheet 2: 需要新增的文件列表\n",
    "    df_to_add = df.loc[files_to_add_indices][['file_name', 'topic', 'category']]\n",
    "    \n",
    "    # Sheet 3: 整体分布统计表\n",
    "    df_stats = pd.DataFrame(stats_list)\n",
    "    df_stats = df_stats[['Topic', 'Original_Ratio', 'Target_Count_Total', 'Existing_In_Groundtruth', 'To_Add', 'Final_Total', 'Status']]\n",
    "\n",
    "    # Sheet 4: 最终完整列表\n",
    "    df_final_list = pd.concat([df_existing, df_to_add])\n",
    "\n",
    "    # --- 6. 写入 Excel ---\n",
    "    print(f\"正在将结果写入 {output_file}...\")\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        df_existing.to_excel(writer, sheet_name='Existing_Distribution', index=False)\n",
    "        df_to_add.to_excel(writer, sheet_name='Files_To_Add', index=False)\n",
    "        df_stats.to_excel(writer, sheet_name='Distribution_Summary', index=False)\n",
    "        df_final_list.to_excel(writer, sheet_name='Final_Full_List', index=False)\n",
    "\n",
    "    print(\"任务完成！\")\n",
    "    print(f\"现有数据: {len(df_existing)}\")\n",
    "    print(f\"建议新增: {len(df_to_add)}\")\n",
    "    print(f\"预计最终总数: {len(df_final_list)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_stratified_dataset()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
