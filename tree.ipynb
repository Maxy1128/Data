{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5e49b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 1. 读取数据\n",
    "df = pd.read_excel('tree.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# 2. 文本预处理函数：只保留 \"ind_xxx\" 这样的特征名\n",
    "# 例如将 \"ind_4e < 1 or missing\" 转化为 \"ind_4e\"\n",
    "def preprocess_rule(text):\n",
    "    import re\n",
    "    # 正则表达式匹配以 ind 开头的特征名\n",
    "    features = re.findall(r\"(ind[\\w_]+)\", str(text))\n",
    "    return \" \".join(features)\n",
    "\n",
    "# 3. 应用预处理\n",
    "df['features_text'] = df['DetailedSplit'].apply(preprocess_rule)\n",
    "\n",
    "# 4. 构建矩阵 (One-Hot Encoding)\n",
    "# binary=True 表示我们只关心“有没有用到这个特征”，不关心用了几次\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X = vectorizer.fit_transform(df['features_text'])\n",
    "\n",
    "# 5. 转化为 DataFrame 查看 (这就是“规则-特征”矩阵)\n",
    "rule_feature_matrix = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# 将原始的 Point（分数）拼回来，方便对照\n",
    "rule_feature_matrix['Score_Points'] = df['Point']\n",
    "\n",
    "print(rule_feature_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45524a65",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 0: 准备工作\n",
    "# ==========================================\n",
    "# 假设这是你所有的 17 个指标名称（请把这里换成你真实的列表）\n",
    "# 即使某些指标在 rules 里一次都没出现，它们也会作为全 0 列出现在结果中\n",
    "all_17_indicators = [\n",
    "    \"ind_4e\", \"ind_13b\", \"ind_3a_1\", \"ind_12f\", \"ind_2a_1\", \n",
    "    \"ind_13a_1\", \"ind_6\", \"ind_7\", \"ind_8\", \"ind_9\", \n",
    "    \"ind_10\", \"ind_11\", \"ind_14\", \"ind_15\", \"ind_16\", \n",
    "    \"ind_17\", \"ind_unused_example\" # 确保这里列出了全部 17 个\n",
    "]\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_excel('tree.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 1: 文本预处理 (保持 210 行不变)\n",
    "# ==========================================\n",
    "# 我们只提取特征名，不拆分行\n",
    "def extract_features(text):\n",
    "    import re\n",
    "    if pd.isna(text): return \"\"\n",
    "    # 提取所有 ind_ 开头的词\n",
    "    feats = re.findall(r\"(ind[\\w_]+)\", str(text))\n",
    "    return \" \".join(feats)\n",
    "\n",
    "df['feature_text'] = df['DetailedSplit'].apply(extract_features)\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 2: 构建矩阵 (强制使用所有 17 个指标)\n",
    "# ==========================================\n",
    "# 关键点：使用 vocabulary 参数！\n",
    "# 这告诉程序：“只关注这17个词，其他的我不要；没出现的词也要给我留列位置。”\n",
    "vectorizer = CountVectorizer(binary=True, vocabulary=all_17_indicators)\n",
    "\n",
    "# 生成矩阵\n",
    "X = vectorizer.fit_transform(df['feature_text'])\n",
    "\n",
    "# 转化为 DataFrame，列名就是我们指定的顺序\n",
    "matrix_df = pd.DataFrame(X.toarray(), columns=all_17_indicators)\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 3: 拼接结果 (加上 Rule 和 Point)\n",
    "# ==========================================\n",
    "# axis=1 表示左右横向拼接\n",
    "final_df = pd.concat([\n",
    "    df[['DetailedSplit', 'Point']],  # 第一列显示 Rule，第二列显示分数\n",
    "    matrix_df                        # 后面跟着 17 列指标矩阵\n",
    "], axis=1)\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 4: 检查与保存\n",
    "# ==========================================\n",
    "print(f\"最终矩阵维度: {final_df.shape}\") \n",
    "# 预期输出: (210, 2 + 17) = (210, 19)\n",
    "\n",
    "# 预览一下\n",
    "print(final_df.head())\n",
    "\n",
    "# 保存结果\n",
    "final_df.to_excel(\"final_rule_matrix.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45672fc7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 0: 准备工作\n",
    "# ==========================================\n",
    "# 您的 17 个指标名称 (请确保这里是全的)\n",
    "all_17_indicators = [\n",
    "    \"ind_4e\", \"ind_13b\", \"ind_3a_1\", \"ind_12f\", \"ind_2a_1\", \n",
    "    \"ind_13a_1\", \"ind_6\", \"ind_7\", \"ind_8\", \"ind_9\", \n",
    "    \"ind_10\", \"ind_11\", \"ind_14\", \"ind_15\", \"ind_16\", \n",
    "    \"ind_17\", \"ind_unused_example\" \n",
    "]\n",
    "\n",
    "# 读取数据\n",
    "# 假设您的第一列是 Index，我们用 index_col=0 读取它，或者把它读作普通列\n",
    "# 这里建议读作普通列，方便我们保存到结果里\n",
    "df = pd.read_excel('tree.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "# 【关键排查点 1】打印刚读进来时的行数\n",
    "print(f\"原始数据行数: {df.shape[0]}\") \n",
    "# 如果这里已经是 421，说明 Excel 文件本身就是脏的（之前存错了）\n",
    "\n",
    "# 假设第一列叫 'Index' (如果不是，请把 df.columns[0] 改成您的列名)\n",
    "index_col_name = df.columns[0] \n",
    "print(f\"我们将使用列 '{index_col_name}' 作为原始索引追踪\")\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 1: 文本预处理 (绝对不进行拆分)\n",
    "# ==========================================\n",
    "def extract_features(text):\n",
    "    import re\n",
    "    if pd.isna(text): return \"\"\n",
    "    feats = re.findall(r\"(ind[\\w_]+)\", str(text))\n",
    "    return \" \".join(feats)\n",
    "\n",
    "df['feature_text'] = df['DetailedSplit'].apply(extract_features)\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 2: 构建矩阵\n",
    "# ==========================================\n",
    "vectorizer = CountVectorizer(binary=True, vocabulary=all_17_indicators)\n",
    "X = vectorizer.fit_transform(df['feature_text'])\n",
    "matrix_df = pd.DataFrame(X.toarray(), columns=all_17_indicators)\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 3: 拼接结果 (带上原始 Index)\n",
    "# ==========================================\n",
    "final_df = pd.concat([\n",
    "    df[[index_col_name, 'DetailedSplit', 'Point']], # 把 Index 列放最前面\n",
    "    matrix_df\n",
    "], axis=1)\n",
    "\n",
    "# ==========================================\n",
    "# 步骤 4: 检查\n",
    "# ==========================================\n",
    "print(f\"最终矩阵维度: {final_df.shape}\")\n",
    "\n",
    "# 如果行数不对，我们通过 Index 看看是谁重复了\n",
    "if final_df.shape[0] > 210:\n",
    "    print(\"\\n警告：行数异常增加！正在查找重复的 Index...\")\n",
    "    duplicates = final_df[final_df.duplicated(subset=[index_col_name], keep=False)]\n",
    "    print(duplicates[[index_col_name, 'DetailedSplit']].head(10))\n",
    "    print(\"\\n如果看到上面的 Index 有重复，说明数据源里这些行被拆分了。\")\n",
    "\n",
    "# 保存\n",
    "final_df.to_excel(\"final_rule_matrix_with_index.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08670d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 读取矩阵\n",
    "df = pd.read_excel(\"final_rule_matrix.xlsx\")\n",
    "\n",
    "# 2. 提取只有 0/1 的特征部分 (假设从第3列开始是特征)\n",
    "# 您的列是: DetailedSplit, Point, ind_1, ind_2 ...\n",
    "feature_cols = df.columns[2:] \n",
    "X = df[feature_cols]\n",
    "\n",
    "# 3. 绘制热力图\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(X, cbar=False, cmap=\"Blues\")\n",
    "plt.title(\"Rule-Feature Heatmap (Dark Blue = Feature Used)\")\n",
    "plt.xlabel(\"Indicators\")\n",
    "plt.ylabel(\"Rule ID\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585af28",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 计算聚类连接矩阵 (使用 Jaccard 距离，适合 binary 数据)\n",
    "# method='average' 或 'complete' 通常效果较好\n",
    "Z = linkage(X, method='average', metric='jaccard')\n",
    "\n",
    "# 2. 绘制树状图 (帮助您决定切成几类)\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(Z)\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"Rule Index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.axhline(y=0.7, c='r', ls='--', lw=2) # 画一条辅助线，看看切在这里会分出几类\n",
    "plt.show()\n",
    "\n",
    "# 3. 真正打标签 (假设我们根据树状图决定切成 8 类)\n",
    "# t=8 表示我们要 8 个簇\n",
    "labels = fcluster(Z, t=8, criterion='maxclust')\n",
    "df['Cluster_Label'] = labels\n",
    "\n",
    "print(df['Cluster_Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0568b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 对每个簇进行聚合分析\n",
    "cluster_profile = df.groupby('Cluster_Label')[feature_cols].mean()\n",
    "\n",
    "# 只要某个特征在该簇的出现率超过 80% (0.8)，我们就认为它是该簇的“核心特征”\n",
    "for cluster_id in cluster_profile.index:\n",
    "    row = cluster_profile.loc[cluster_id]\n",
    "    core_features = row[row > 0.8].index.tolist()\n",
    "    \n",
    "    # 计算该簇的平均风险分\n",
    "    avg_score = df[df['Cluster_Label'] == cluster_id]['Point'].mean()\n",
    "    \n",
    "    print(f\"=== Cluster {cluster_id} (风险分: {avg_score:.1f}) ===\")\n",
    "    print(f\"核心特征: {core_features}\")\n",
    "    print(f\"规则数量: {len(df[df['Cluster_Label'] == cluster_id])}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb36fc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.stripplot(x=\"Cluster_Label\", y=\"Point\", data=df, jitter=0.2, size=5)\n",
    "plt.title(\"Score Distribution by Cluster\")\n",
    "plt.axhline(0, color='red', linestyle='--') # 0分线\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
